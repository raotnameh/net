{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full train and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from data import input_data\n",
    "from model import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of classes in valid are :  10\n",
      "size of data 9984\n",
      "total number of classes in valid are :  10\n",
      "size of data 996\n"
     ]
    }
   ],
   "source": [
    "criterion_d = nn.CrossEntropyLoss()\n",
    "input_train = input_data(root_dir = \"/home/hemant/net/easy_net/data/train/\", type = \"valid\")\n",
    "train_dl =  DataLoader(input_train, batch_size=32,shuffle=True, num_workers=4)\n",
    "input_valid = input_data(root_dir = \"/home/hemant/net/easy_net/data/test/\", type = \"valid\")\n",
    "valid_dl =  DataLoader(input_valid, batch_size=64,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "model = nn.Sequential(  feature_b(),\n",
    "                        feature_r(),\n",
    "                        decision(out_classes = input_train[0][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "rank = \"2\"\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "device = torch.device(\"cuda:\"+rank)\n",
    "model.to(device)\n",
    "model.load_state_dict(torch.load(\"../weights/full.pth\",map_location=\"cuda:\"+str(rank)),strict=True)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start of epoch:  1\n",
      "[1,    25] loss: 122.561\n",
      "[1,    50] loss: 53.568\n",
      "[1,    75] loss: 51.636\n",
      "[1,   100] loss: 46.567\n",
      "[1,   125] loss: 44.974\n",
      "[1,   150] loss: 44.451\n",
      "[1,   175] loss: 45.481\n",
      "[1,   200] loss: 42.128\n",
      "[1,   225] loss: 43.484\n",
      "[1,   250] loss: 42.420\n",
      "[1,   275] loss: 40.702\n",
      "[1,   300] loss: 39.383\n",
      " It took :  1.4370009938875834  mins for the last training epoch\n",
      "accuracy and val loss is :  39.2570281124498 , 0.0  --AND--   It took :  8.754870653152466  seconds \n",
      "start of epoch:  2\n",
      "[2,    25] loss: 40.824\n",
      "[2,    50] loss: 38.377\n",
      "[2,    75] loss: 35.986\n",
      "[2,   100] loss: 40.006\n",
      "[2,   125] loss: 38.449\n",
      "[2,   150] loss: 39.213\n",
      "[2,   175] loss: 35.729\n",
      "[2,   200] loss: 39.031\n",
      "[2,   225] loss: 38.075\n",
      "[2,   250] loss: 35.681\n",
      "[2,   275] loss: 37.665\n",
      "[2,   300] loss: 39.121\n",
      " It took :  1.5198408365249634  mins for the last training epoch\n",
      "accuracy and val loss is :  41.06425702811245 , 0.0  --AND--   It took :  9.456006526947021  seconds \n",
      "start of epoch:  3\n",
      "[3,    25] loss: 34.506\n",
      "[3,    50] loss: 35.565\n",
      "[3,    75] loss: 32.436\n",
      "[3,   100] loss: 34.943\n",
      "[3,   125] loss: 34.245\n",
      "[3,   150] loss: 36.455\n",
      "[3,   175] loss: 36.302\n",
      "[3,   200] loss: 34.032\n",
      "[3,   225] loss: 34.139\n",
      "[3,   250] loss: 33.429\n",
      "[3,   275] loss: 32.747\n",
      "[3,   300] loss: 32.535\n",
      " It took :  1.4291662255922952  mins for the last training epoch\n",
      "accuracy and val loss is :  47.89156626506024 , 0.0  --AND--   It took :  6.833771228790283  seconds \n",
      "start of epoch:  4\n",
      "[4,    25] loss: 29.810\n",
      "[4,    50] loss: 32.943\n",
      "[4,    75] loss: 31.271\n",
      "[4,   100] loss: 32.632\n",
      "[4,   125] loss: 33.334\n",
      "[4,   150] loss: 35.338\n",
      "[4,   175] loss: 30.560\n",
      "[4,   200] loss: 30.444\n",
      "[4,   225] loss: 27.442\n",
      "[4,   250] loss: 34.068\n",
      "[4,   275] loss: 31.121\n",
      "[4,   300] loss: 30.654\n",
      " It took :  1.376321268081665  mins for the last training epoch\n",
      "accuracy and val loss is :  51.907630522088354 , 0.0  --AND--   It took :  8.988583087921143  seconds \n",
      "start of epoch:  5\n",
      "[5,    25] loss: 28.920\n",
      "[5,    50] loss: 28.606\n",
      "[5,    75] loss: 28.863\n",
      "[5,   100] loss: 31.273\n",
      "[5,   125] loss: 27.685\n",
      "[5,   150] loss: 28.880\n",
      "[5,   175] loss: 27.530\n",
      "[5,   200] loss: 27.737\n",
      "[5,   225] loss: 27.980\n",
      "[5,   250] loss: 31.927\n",
      "[5,   275] loss: 26.528\n",
      "[5,   300] loss: 26.569\n",
      " It took :  1.5018169164657593  mins for the last training epoch\n",
      "accuracy and val loss is :  57.329317269076306 , 0.0  --AND--   It took :  8.86022162437439  seconds \n",
      "start of epoch:  6\n",
      "[6,    25] loss: 22.950\n",
      "[6,    50] loss: 27.528\n",
      "[6,    75] loss: 27.184\n",
      "[6,   100] loss: 26.395\n",
      "[6,   125] loss: 26.079\n",
      "[6,   150] loss: 22.611\n",
      "[6,   175] loss: 30.324\n",
      "[6,   200] loss: 25.782\n",
      "[6,   225] loss: 26.678\n",
      "[6,   250] loss: 26.399\n",
      "[6,   275] loss: 25.706\n",
      "[6,   300] loss: 25.376\n",
      " It took :  1.4751176516215005  mins for the last training epoch\n",
      "accuracy and val loss is :  51.204819277108435 , 0.0  --AND--   It took :  8.629815340042114  seconds \n",
      "start of epoch:  7\n",
      "[7,    25] loss: 24.499\n",
      "[7,    50] loss: 23.488\n",
      "[7,    75] loss: 24.869\n",
      "[7,   100] loss: 21.877\n",
      "[7,   125] loss: 24.392\n",
      "[7,   150] loss: 23.075\n",
      "[7,   175] loss: 26.106\n",
      "[7,   200] loss: 23.295\n",
      "[7,   225] loss: 22.184\n",
      "[7,   250] loss: 25.258\n",
      "[7,   275] loss: 24.850\n",
      "[7,   300] loss: 27.246\n",
      " It took :  1.4494232614835103  mins for the last training epoch\n",
      "accuracy and val loss is :  53.81526104417671 , 0.0  --AND--   It took :  8.64503288269043  seconds \n",
      "start of epoch:  8\n",
      "[8,    25] loss: 22.959\n",
      "[8,    50] loss: 23.980\n",
      "[8,    75] loss: 23.090\n",
      "[8,   100] loss: 20.310\n",
      "[8,   125] loss: 20.770\n",
      "[8,   150] loss: 23.448\n",
      "[8,   175] loss: 22.629\n",
      "[8,   200] loss: 23.502\n",
      "[8,   225] loss: 22.925\n",
      "[8,   250] loss: 22.067\n",
      "[8,   275] loss: 26.125\n",
      "[8,   300] loss: 21.011\n",
      " It took :  1.4435788154602052  mins for the last training epoch\n",
      "accuracy and val loss is :  53.6144578313253 , 0.0  --AND--   It took :  8.489877223968506  seconds \n",
      "start of epoch:  9\n",
      "[9,    25] loss: 17.523\n",
      "[9,    50] loss: 20.755\n",
      "[9,    75] loss: 19.631\n",
      "[9,   100] loss: 20.096\n",
      "[9,   125] loss: 22.322\n",
      "[9,   150] loss: 22.715\n",
      "[9,   175] loss: 18.026\n",
      "[9,   200] loss: 21.088\n",
      "[9,   225] loss: 25.030\n",
      "[9,   250] loss: 20.885\n",
      "[9,   275] loss: 19.868\n",
      "[9,   300] loss: 18.871\n",
      " It took :  1.4635104616483052  mins for the last training epoch\n",
      "accuracy and val loss is :  65.96385542168674 , 0.0  --AND--   It took :  8.45453429222107  seconds \n",
      "start of epoch:  10\n",
      "[10,    25] loss: 20.550\n",
      "[10,    50] loss: 20.203\n",
      "[10,    75] loss: 19.141\n",
      "[10,   100] loss: 20.022\n",
      "[10,   125] loss: 19.182\n",
      "[10,   150] loss: 21.344\n",
      "[10,   175] loss: 18.429\n",
      "[10,   200] loss: 17.539\n",
      "[10,   225] loss: 18.569\n",
      "[10,   250] loss: 21.726\n",
      "[10,   275] loss: 19.968\n",
      "[10,   300] loss: 18.803\n",
      " It took :  1.4970364133516947  mins for the last training epoch\n",
      "accuracy and val loss is :  59.43775100401606 , 0.0  --AND--   It took :  8.660080432891846  seconds \n",
      "start of epoch:  11\n",
      "[11,    25] loss: 18.176\n",
      "[11,    50] loss: 15.915\n",
      "[11,    75] loss: 15.574\n",
      "[11,   100] loss: 19.573\n",
      "[11,   125] loss: 19.720\n",
      "[11,   150] loss: 17.158\n",
      "[11,   175] loss: 20.551\n",
      "[11,   200] loss: 18.092\n",
      "[11,   225] loss: 19.122\n",
      "[11,   250] loss: 17.791\n",
      "[11,   275] loss: 17.380\n",
      "[11,   300] loss: 16.485\n",
      " It took :  1.4827489097913107  mins for the last training epoch\n",
      "accuracy and val loss is :  57.028112449799195 , 0.0  --AND--   It took :  9.136653661727905  seconds \n",
      "start of epoch:  12\n",
      "[12,    25] loss: 14.896\n",
      "[12,    50] loss: 15.746\n",
      "[12,    75] loss: 18.570\n",
      "[12,   100] loss: 17.017\n",
      "[12,   125] loss: 16.396\n",
      "[12,   150] loss: 17.930\n",
      "[12,   175] loss: 15.898\n",
      "[12,   200] loss: 19.023\n",
      "[12,   225] loss: 17.776\n",
      "[12,   250] loss: 16.813\n",
      "[12,   275] loss: 16.739\n",
      "[12,   300] loss: 14.463\n",
      " It took :  1.4400143504142762  mins for the last training epoch\n",
      "accuracy and val loss is :  56.827309236947784 , 0.0  --AND--   It took :  8.427926540374756  seconds \n",
      "start of epoch:  13\n",
      "[13,    25] loss: 14.756\n",
      "[13,    50] loss: 13.458\n",
      "[13,    75] loss: 15.309\n",
      "[13,   100] loss: 17.510\n",
      "[13,   125] loss: 16.480\n",
      "[13,   150] loss: 16.396\n",
      "[13,   175] loss: 13.692\n",
      "[13,   200] loss: 14.980\n",
      "[13,   225] loss: 16.633\n",
      "[13,   250] loss: 17.241\n",
      "[13,   275] loss: 15.416\n",
      "[13,   300] loss: 17.376\n",
      " It took :  1.4676269888877869  mins for the last training epoch\n"
     ]
    }
   ],
   "source": [
    "accuracy = 0\n",
    "for j in range(20):\n",
    "    print(\"start of epoch: \", j+1)\n",
    "    #Training\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    start = time()\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "        out = model(input)\n",
    "\n",
    "        loss = criterion_d(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # print every 25 mini-batches\n",
    "        if i % 25 == 24:\n",
    "            print('[%d, %5d] loss: %.3f' %(j + 1, i + 1, running_loss))\n",
    "            running_loss = 0\n",
    "    end = time()\n",
    "    print(\" It took : \", (end - start)/60, \" mins for the last training epoch\")\n",
    "    \n",
    "    running_loss, acc, num, length = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        start = time()\n",
    "        for i, data in enumerate(valid_dl, 0):\n",
    "            model.eval()\n",
    "\n",
    "            input, target, img_name, number_of_class = data\n",
    "            input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "            out = model(input)\n",
    "\n",
    "            loss = criterion_d(out, target)\n",
    "\n",
    "            out , predicted = torch.max(out, 1)\n",
    "            for k in range(len(target)):\n",
    "                if target[k] == predicted[k].item():\n",
    "                    num = num + 1\n",
    "            length = length + len(target)\n",
    "        acc = (num/length)*100\n",
    "        end = time()\n",
    "        if acc>accuracy:\n",
    "            torch.save(model.state_dict(),\"../weights/full.pth\")\n",
    "            accuracy = acc\n",
    "        print(\"accuracy and val loss is : \",acc,\",\",running_loss/(i+1), \" --AND-- \", \" It took : \", (end - start), \" seconds \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "running_loss, acc, num, length = 0, 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    start = time()\n",
    "    for i, data in enumerate(valid_dl, 0):\n",
    "        model.eval()\n",
    "\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "        out = model(input)\n",
    "\n",
    "        loss = criterion_d(out, target)\n",
    "\n",
    "        out , predicted = torch.max(out, 1)\n",
    "        for k in range(len(target)):\n",
    "            if target[k] == predicted[k].item():\n",
    "                num = num + 1\n",
    "        length = length + len(target)\n",
    "    acc = (num/length)*100\n",
    "    end = time()\n",
    "    print(\"accuracy and val loss is : \",acc,\",\",running_loss/(i+1), \" --AND-- \", \" It took : \", (end - start), \" seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

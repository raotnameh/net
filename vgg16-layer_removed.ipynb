{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data import input_data\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=\"imagenet\")\n",
    "vgg16.classifier = nn.Sequential(nn.Linear(25088,4096),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Dropout(0.5,inplace=False),\n",
    "                                nn.Linear(4096,4096),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Dropout(0.5,inplace=False),\n",
    "                                nn.Linear(4096,10))\n",
    "vgg16.load_state_dict(torch.load(\"../weights/vgg16.pth\"))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = nn.Sequential(nn.Conv2d(3,64,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(64,64,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(64,128,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(128,128,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(128,256,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256,256,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256,256,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(256,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1))\n",
    "\n",
    "vgg16.features = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = []\n",
    "for i in mode.state_dict().keys():\n",
    "    f.append(((i,vgg16.features.state_dict()[i])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16.features.load_state_dict(OrderedDict(f))\n",
    "vgg16.to(device)\n",
    "device = torch.device(\"cuda:2\")\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.0001)\n",
    "criterion_d = nn.CrossEntropyLoss()\n",
    "input_train = input_data(root_dir = \"/home/hemant/net/easy_net/data/train/\", type = \"valid\")\n",
    "train_dl =  DataLoader(input_train, batch_size=64,shuffle=True, num_workers=4)\n",
    "input_valid = input_data(root_dir = \"/home/hemant/net/easy_net/data/test/\", type = \"valid\")\n",
    "valid_dl =  DataLoader(input_valid, batch_size=64,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat = 0\n",
    "for j in range(50):\n",
    "    print(\"start of epoch: \", j+1)\n",
    "    #Training\n",
    "    running_loss = 0\n",
    "    start = time()\n",
    "    vgg16.train()\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "        out = vgg16(input)\n",
    "\n",
    "        loss = criterion_d(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # print every 25 mini-batches\n",
    "        if i % 25 == 24:\n",
    "            print('[%d, %5d] loss: %.3f' %(j + 1, i + 1, running_loss))\n",
    "            running_loss = 0\n",
    "    end = time()\n",
    "    print(\"It took : \", (end - start)/60, \" mins for the last training epoch\")\n",
    "    \n",
    "    running_loss, acc, num, length = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        start = time()\n",
    "        for i, data in tqdm(enumerate(valid_dl, 0),total=len(valid_dl), unit=\"images\",position=0,leave=True):\n",
    "            vgg16.eval()\n",
    "\n",
    "            input, target, img_name, number_of_class = data\n",
    "            input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "            out = vgg16(input)\n",
    "\n",
    "            loss = criterion_d(out, target)\n",
    "            running_loss += loss.cpu().numpy()\n",
    "            out , predicted = torch.max(out, 1)\n",
    "            for k in range(len(target)):\n",
    "                if target[k] == predicted[k].item():\n",
    "                    num = num + 1\n",
    "            length = length + len(target)\n",
    "        acc = (num/length)*100\n",
    "        end = time()\n",
    "        print(\"accuracy and val loss is : \",acc,\",\",running_loss/(i+1), \" --AND-- \", \" It took : \", (end - start), \" seconds \")\n",
    "    \n",
    "    if acc > stat:\n",
    "        stat = acc\n",
    "        torch.save(vgg16.state_dict(),\"../weights/\" + \"vgg16\" + \".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "running_loss, acc, num, length = 0, 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    start = time()\n",
    "    for i, data in tqdm(enumerate(valid_dl, 0),total=len(valid_dl), unit=\"images\",position=0,leave=True):\n",
    "        vgg16.eval()\n",
    "\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "        \n",
    "        out = vgg16(input)\n",
    "        \n",
    "        loss = criterion_d(out, target)\n",
    "        running_loss+=loss.cpu().numpy()\n",
    "\n",
    "        out , predicted = torch.max(out, 1)\n",
    "        for k in range(len(target)):\n",
    "            if target[k] == predicted[k].item():\n",
    "                num = num + 1\n",
    "        length = length + len(target)\n",
    "    acc = (num/length)*100\n",
    "    end = time()\n",
    "    print(\"accuracy and val loss is : \",np.round(acc,3),\",\",np.round(running_loss/(i+1),3), \" --AND-- \", \" It took : \", (end - start), \" seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vgg16.state_dict(),\"../weights/\" + \"vgg16_layer_removed\" + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

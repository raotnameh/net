{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "from time import time\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from data import input_data\n",
    "import numpy as np\n",
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vgg16 = models.vgg16(pretrained=\"imagenet\")\n",
    "device = torch.device(\"cuda:2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VGG:\n\tUnexpected key(s) in state_dict: \"features.28.weight\", \"features.28.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-87ca090a1cf9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                 \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                 nn.Linear(4096,10))\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mvgg16\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../weights/vgg16.pth\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/deep/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    837\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 839\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    840\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VGG:\n\tUnexpected key(s) in state_dict: \"features.28.weight\", \"features.28.bias\". "
     ]
    }
   ],
   "source": [
    "vgg16.classifier = nn.Sequential(nn.Linear(25088,4096),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Dropout(0.5,inplace=False),\n",
    "                                nn.Linear(4096,4096),\n",
    "                                nn.ReLU(True),\n",
    "                                nn.Dropout(0.5,inplace=False),\n",
    "                                nn.Linear(4096,10))\n",
    "vgg16.load_state_dict(torch.load(\"../weights/vgg16.pth\"))\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mode = nn.Sequential(nn.Conv2d(3,64,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(64,64,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(64,128,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(128,128,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(128,256,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256,256,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(256,256,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(256,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.Conv2d(512,512,3,1,1),\n",
    "                nn.ReLU(True),\n",
    "                nn.MaxPool2d(2,2,0,1))\n",
    "\n",
    "vgg16.features = mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f = []\n",
    "for i in mode.state_dict().keys():\n",
    "    f.append(((i,vgg16.features.state_dict()[i])))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vgg16.features.load_state_dict(OrderedDict(f))\n",
    "vgg16.to(device)\n",
    "print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of classes in valid are :  10\n",
      "size of data 9984\n",
      "total number of classes in valid are :  10\n",
      "size of data 996\n"
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(vgg16.parameters(), lr=0.0001)\n",
    "criterion_d = nn.CrossEntropyLoss()\n",
    "input_train = input_data(root_dir = \"/home/hemant/net/easy_net/data/train/\", type = \"valid\")\n",
    "train_dl =  DataLoader(input_train, batch_size=64,shuffle=True, num_workers=4)\n",
    "input_valid = input_data(root_dir = \"/home/hemant/net/easy_net/data/test/\", type = \"valid\")\n",
    "valid_dl =  DataLoader(input_valid, batch_size=64,shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "stat = 0\n",
    "for j in range(50):\n",
    "    print(\"start of epoch: \", j+1)\n",
    "    #Training\n",
    "    running_loss = 0\n",
    "    start = time()\n",
    "    vgg16.train()\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "        out = vgg16(input)\n",
    "\n",
    "        loss = criterion_d(out, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # print every 25 mini-batches\n",
    "        if i % 25 == 24:\n",
    "            print('[%d, %5d] loss: %.3f' %(j + 1, i + 1, running_loss))\n",
    "            running_loss = 0\n",
    "    end = time()\n",
    "    print(\"It took : \", (end - start)/60, \" mins for the last training epoch\")\n",
    "    \n",
    "    running_loss, acc, num, length = 0, 0, 0, 0\n",
    "    with torch.no_grad():\n",
    "        start = time()\n",
    "        for i, data in tqdm(enumerate(valid_dl, 0),total=len(valid_dl), unit=\"images\",position=0,leave=True):\n",
    "            vgg16.eval()\n",
    "\n",
    "            input, target, img_name, number_of_class = data\n",
    "            input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "            out = vgg16(input)\n",
    "\n",
    "            loss = criterion_d(out, target)\n",
    "            running_loss += loss.cpu().numpy()\n",
    "            out , predicted = torch.max(out, 1)\n",
    "            for k in range(len(target)):\n",
    "                if target[k] == predicted[k].item():\n",
    "                    num = num + 1\n",
    "            length = length + len(target)\n",
    "        acc = (num/length)*100\n",
    "        end = time()\n",
    "        print(\"accuracy and val loss is : \",acc,\",\",running_loss/(i+1), \" --AND-- \", \" It took : \", (end - start), \" seconds \")\n",
    "    \n",
    "    if acc > stat:\n",
    "        stat = acc\n",
    "        torch.save(vgg16.state_dict(),\"../weights/\" + \"vgg16\" + \".pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6057c1a829d143dfa6d625cf492b9c70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "accuracy and val loss is :  8.936 , 89.225  --AND--   It took :  7.406770706176758  seconds \n"
     ]
    }
   ],
   "source": [
    "running_loss, acc, num, length = 0, 0, 0, 0\n",
    "with torch.no_grad():\n",
    "    start = time()\n",
    "    for i, data in tqdm(enumerate(valid_dl, 0),total=len(valid_dl), unit=\"images\",position=0,leave=True):\n",
    "        vgg16.eval()\n",
    "\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "        \n",
    "        out = vgg16(input)\n",
    "        \n",
    "        loss = criterion_d(out, target)\n",
    "        running_loss+=loss.cpu().numpy()\n",
    "\n",
    "        out , predicted = torch.max(out, 1)\n",
    "        for k in range(len(target)):\n",
    "            if target[k] == predicted[k].item():\n",
    "                num = num + 1\n",
    "        length = length + len(target)\n",
    "    acc = (num/length)*100\n",
    "    end = time()\n",
    "    print(\"accuracy and val loss is : \",np.round(acc,3),\",\",np.round(running_loss/(i+1),3), \" --AND-- \", \" It took : \", (end - start), \" seconds \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(vgg16.state_dict(),\"../weights/\" + \"vgg16_layer_removed\" + \".pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

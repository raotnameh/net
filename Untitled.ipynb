{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of classes in train : , 10\n",
      "number of classes in valid : , 10\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from time import time\n",
    "\n",
    "from utils import *\n",
    "from data import input_data\n",
    "from model import feature_b, feature_r, decision_r, gru_layer\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"3\"\n",
    "\n",
    "total_acc = ''\n",
    "\n",
    "epochs= 1\n",
    "batch_size=32\n",
    "learning_rate=0.0001\n",
    "cuda = True\n",
    "steps=1\n",
    "gpu_rank=3\n",
    "data_valid = 'data/val/'\n",
    "data_train='data/train/'\n",
    "\n",
    "input_train = input_data(root_dir = data_train, type = \"train\")\n",
    "train_dl =  DataLoader(input_train, batch_size=batch_size,shuffle=True, num_workers=4)\n",
    "\n",
    "input_valid = input_data(root_dir = data_valid, type = \"valid\")\n",
    "valid_dl =  DataLoader(input_valid, batch_size=64,shuffle=False, num_workers=4)\n",
    "\n",
    "# data sample: image, landmarks, img_name, self.number_of_class\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no of parameters is : 96.146 Million\n"
     ]
    }
   ],
   "source": [
    "base_feature = feature_b()\n",
    "base_decision = decision_r()\n",
    "model = [[base_feature, base_decision]]\n",
    "if steps >=1 :\n",
    "    recursive_layers = [[f\"feature_{i}\", f\"decision_{i}\"] for i in range(1,steps+1)]\n",
    "    for i in recursive_layers:\n",
    "        model.append([feature_r(),decision_r()])\n",
    "\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "if gpu_rank == True and cuda:\n",
    "    torch.cuda.set_device(int(gpu_rank))\n",
    "\n",
    "# if weights == True:\n",
    "# \tfeature_1.load_state_dict(torch.load(\"../weights/final_feature_1.pth\",map_location=\"cuda:\"+str(gpu_rank)), strict = True)\n",
    "\n",
    "for layer in model:\n",
    "    for sub_layer in layer:\n",
    "        for params in sub_layer.parameters():\n",
    "            params.requires_grad = True\n",
    "\n",
    "for i in model:\n",
    "    for j in i:\n",
    "        j.to(device)\n",
    "\n",
    "hidden_size = 128\n",
    "rnn_layer = gru_layer(4096, hidden_size,batch_first=False, classes = input_train.classes()).to(device)\n",
    "\n",
    "optimizers = []\n",
    "for rank, layers in enumerate(model):\n",
    "    optimizers.append(optim.Adam(list(layers[0].parameters()) + list(layers[1].parameters()), lr=learning_rate))\n",
    "    optimizers[rank].zero_grad()\n",
    "\n",
    "opti = optim.Adam(rnn_layer.parameters(), lr=learning_rate)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# print(model)\n",
    "print(f\"no of parameters is : {((get_param_size([j for i in model for j in i]))/1000000):.3f} Million\")\n",
    "accuracy = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(int(epochs)):\n",
    "\n",
    "    [w.train() for q in model for w in q]\t#Training\n",
    "    rnn_layer.train()\n",
    "    running_loss = [0.0, 0.0]\n",
    "    print(\"start of epoch: \", j+1)\n",
    "    start = time()\n",
    "    for i, data in enumerate(train_dl, 0):\n",
    "        #input data\n",
    "        input, target, img_name, number_of_class = data\n",
    "        input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "        #1st layer\n",
    "        f_1 = model[0][0](input)\n",
    "        d_1 = model[0][1](f_1)\n",
    "        #2nd layer\n",
    "        f_2 = model[1][0](f_1.clone().detach())\n",
    "        d_2 = model[1][1](f_2)\n",
    "        #concatenate the output from all the convolution layer to feed it to the rnn layer in one step\n",
    "        out = torch.cat((d_1,d_2)).view(2,d_2.shape[0],-1)\n",
    "        #rnn layer\n",
    "        hidden_layer = torch.zeros(1,d_2.shape[0], hidden_size,dtype=torch.float32).to(device)\n",
    "        out = rnn_layer(out,hidden_layer)\n",
    "\n",
    "        #loss at each time step\n",
    "        loss = []\n",
    "        for k in range(steps+1):\n",
    "            loss.append(criterion(out[:,k,:],target))\n",
    "#         calulating loss for each tiem step\n",
    "        for r, l in enumerate(loss):\n",
    "            l.backward(retain_graph=True)\n",
    "            running_loss[r] += l.item()\n",
    "\n",
    "#         optimizer step\n",
    "        opti.step()\n",
    "        for m in optimizers:\n",
    "        \tm.step()\n",
    "        for jk in optimizers:\n",
    "        \tjk.zero_grad()\n",
    "        opti.zero_grad()\n",
    "\n",
    "        # print every 25 mini-batches\n",
    "        if i % 5 == 5 - 1:\t\n",
    "            print('[%d, %5d] loss1: %.3f, loss2: %.3f' %(j + 1, i + 1, running_loss[0]/5, running_loss[1]/5))\n",
    "            running_loss = [0.0, 0.0]\n",
    "\n",
    "    end = time()\n",
    "    print(f\"It took : {((end - start)/60):.2f} mins for the training step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7dcfc3b50634546a00f164cb70a4c47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy and val loss is : 10.938--0.136 -AND- It took : 25.03 seconds for the evaluation step.\n",
      "Accuracy and val loss is : 10.938--0.135 -AND- It took : 25.03 seconds for the evaluation step.\n"
     ]
    }
   ],
   "source": [
    "# Validation\n",
    "    running_loss, acc, num, length =  [0, 0], [0, 0],  [0, 0], 0\n",
    "    with torch.no_grad():\n",
    "        start = time()\n",
    "        [w.train() for q in model for w in q] #evaluation\n",
    "        rnn_layer.eval()\n",
    "        for i, data in tqdm(enumerate(valid_dl, 0)):\t\n",
    "\n",
    "            input, target, img_name, number_of_class = data\n",
    "            input, target = (input.type(torch.float32)).to(device), target.to(device)\n",
    "\n",
    "            f_1 = model[0][0](input)\n",
    "            d_1 = model[0][1](f_1)\n",
    "\n",
    "            f_2 = model[1][0](f_1.clone().detach())\n",
    "            d_2 = model[1][1](f_2)\n",
    "\n",
    "            out = torch.cat((d_1,d_2)).view(2,d_2.shape[0],-1)\n",
    "            hidden_layer = torch.zeros(1,d_2.shape[0], hidden_size,dtype=torch.float32).to(device)\n",
    "            out = rnn_layer(out,hidden_layer)\n",
    "\n",
    "            for k in range(steps+1):\n",
    "                loss = criterion(out[:,k,:],target)\n",
    "                running_loss[k] += loss.item()\n",
    "\n",
    "                _, predicted = torch.max(out[:,k,:], 1)\n",
    "                for df in range(len(target)):\n",
    "                    if target[df] == predicted[df].item():\n",
    "                        num[k] += 1\n",
    "            length = length + len(target)\n",
    "            break\n",
    "\n",
    "        for i in range(len(acc)):\n",
    "            acc[i] = (num[i]/length)*100\n",
    "        end = time()\n",
    "        [print(f\"Accuracy and val loss is : {acc[i]:.3f}--{running_loss[i]/(len(valid_dl)+1):.3f} -AND- It took : {(end - start):.2f} seconds for the evaluation step.\") for i in range(len(acc))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
